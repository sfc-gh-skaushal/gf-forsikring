{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# üîç Fraud Detection Model with Snowpark ML\n\n## InsuranceCo - Snowflake Horizon Demo\n\nThis notebook demonstrates how Data Scientists can build ML models directly on governed data in Snowflake using Snowpark. Key points:\n\n- **Data stays in Snowflake** - no data movement required\n- **Governance policies apply** - PII is accessible only to DATA_SCIENTIST role\n- **Full lineage tracking** - model inputs are traced back to source\n- **Scalable compute** - leverage Snowflake warehouses for training\n\n---",
      "id": "a9691646-bf2e-449b-adf4-d3424f22e07c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Setup and Connection",
      "id": "fbac4313-2526-4590-ab48-972b9a517fc8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Import required libraries\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col, when, lit, avg, sum as sum_, count, corr\nfrom snowflake.snowpark.types import FloatType, IntegerType, StringType\nfrom snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport pandas as pd\nimport numpy as np\n\nprint(\"‚úÖ Libraries imported successfully\")",
      "id": "687024c0-27d7-4921-8a77-349ed1810d16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Create Snowpark session\n# When running in Snowsight Notebooks, session is automatically available via get_active_session()\n\n# For Snowsight notebooks (recommended):\nsession = get_active_session()\n\n# For local development, uncomment and configure:\n# connection_parameters = {\n#     \"account\": \"<your-account>\",\n#     \"user\": \"<your-username>\",\n#     \"password\": \"<your-password>\",  # Use key-pair auth in production\n#     \"role\": \"DATA_SCIENTIST\",\n#     \"warehouse\": \"INSURANCECO_ML_WH\",\n#     \"database\": \"INSURANCECO\",\n#     \"schema\": \"DATA_SCIENCE\"\n# }\n# session = Session.builder.configs(connection_parameters).create()\n\nprint(f\"‚úÖ Connected to Snowflake\")\nprint(f\"   Role: {session.get_current_role()}\")\nprint(f\"   Warehouse: {session.get_current_warehouse()}\")\nprint(f\"   Database: {session.get_current_database()}\")",
      "id": "f35a6f40-f7c1-4915-9423-3e44a8e783dd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load Governed Data\n\nWe load data from the curated `DIM_CLAIMS` table. As a DATA_SCIENTIST, we have full access to PII fields (required for fraud pattern analysis). Other roles would see masked data.",
      "id": "bd70d686-1e93-4b22-99c1-0a218d83f5af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Load claims data from curated layer\nclaims_df = session.table(\"INSURANCECO.CURATED.DIM_CLAIMS\")\n\n# Load policy data for enrichment\npolicies_df = session.table(\"INSURANCECO.CURATED.DIM_POLICIES\")\n\nprint(f\"üìä Loaded {claims_df.count()} claims records\")\nprint(f\"üìä Loaded {policies_df.count()} policy records\")\n\n# Preview the data (PII visible because we're DATA_SCIENTIST)\nprint(\"\\nüîì DATA_SCIENTIST role can see full PII:\")\nclaims_df.select(\n    \"CLAIM_ID\", \n    \"POLICY_HOLDER_NAME\",  # PII - visible to DATA_SCIENTIST\n    \"POLICY_HOLDER_EMAIL\", # PII - visible to DATA_SCIENTIST  \n    \"CLAIM_AMOUNT\",\n    \"FRAUD_FLAG\"\n).show(5)",
      "id": "f886f858-8907-4e10-8d2b-ad9f8c4d23b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Exploratory Data Analysis",
      "id": "966a3f26-7663-4c72-a142-a9888c1516a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Analyze fraud distribution\nfraud_dist = claims_df.group_by(\"FRAUD_FLAG\").agg(\n    count(\"*\").alias(\"COUNT\"),\n    avg(\"CLAIM_AMOUNT\").alias(\"AVG_CLAIM_AMOUNT\"),\n    avg(\"COVERAGE_UTILIZATION_PCT\").alias(\"AVG_COVERAGE_UTIL\")\n)\n\nprint(\"üìä Fraud vs Non-Fraud Distribution:\")\nfraud_dist.show()\n\n# Analyze claims that exceed coverage (potential fraud indicator)\nexceeds_coverage = claims_df.filter(col(\"EXCEEDS_COVERAGE\") == True)\nprint(f\"\\n‚ö†Ô∏è Claims exceeding coverage: {exceeds_coverage.count()}\")\nprint(\"\\nüìã Details of claims exceeding coverage:\")\nexceeds_coverage.select(\n    \"CLAIM_ID\",\n    \"CLAIM_AMOUNT\",\n    \"POLICY_COVERAGE_LIMIT\",\n    \"COVERAGE_UTILIZATION_PCT\",\n    \"FRAUD_FLAG\",\n    \"ADJUSTER_NOTES\"\n).show()",
      "id": "8d9af511-3833-42f3-9b6f-bac8d9b42f62"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Feature Engineering\n\nCreate features for the fraud detection model using Snowpark transformations.",
      "id": "433df240-062a-4b4e-bfdf-49ad3a65f55d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Join claims with policies for enriched features\nenriched_df = claims_df.join(\n    policies_df.select(\n        \"POLICY_ID\",\n        col(\"RISK_SCORE\").alias(\"POLICY_RISK_SCORE\"),\n        col(\"PREVIOUS_CLAIMS_COUNT\").alias(\"PREV_CLAIMS\"),\n        col(\"DRIVER_AGE\").alias(\"DRIVER_AGE\"),\n        col(\"YEARS_LICENSED\").alias(\"YEARS_LICENSED\"),\n        col(\"POLICY_TYPE\").alias(\"POLICY_TYPE\"),\n        col(\"PREMIUM_ANNUAL\").alias(\"PREMIUM\")\n    ),\n    on=\"POLICY_ID\"\n)\n\n# Create derived features\nfeature_df = enriched_df.select(\n    col(\"CLAIM_ID\"),\n    col(\"FRAUD_FLAG\").cast(IntegerType()).alias(\"IS_FRAUD\"),\n    col(\"CLAIM_AMOUNT\"),\n    col(\"COVERAGE_UTILIZATION_PCT\"),\n    col(\"DAYS_TO_REPORT\"),\n    col(\"CLAIM_TYPE\"),\n    col(\"EXCEEDS_COVERAGE\").cast(IntegerType()).alias(\"EXCEEDS_COVERAGE\"),\n    col(\"HIGH_VALUE_CLAIM\").cast(IntegerType()).alias(\"HIGH_VALUE\"),\n    col(\"VEHICLE_AGE\"),\n    col(\"POLICY_RISK_SCORE\"),\n    col(\"PREV_CLAIMS\"),\n    col(\"DRIVER_AGE\"),\n    col(\"YEARS_LICENSED\"),\n    col(\"POLICY_TYPE\"),\n    (col(\"CLAIM_AMOUNT\") / col(\"PREMIUM\")).alias(\"CLAIM_PREMIUM_RATIO\")\n)\n\nprint(f\"‚úÖ Created feature DataFrame with {len(feature_df.columns)} columns\")\nfeature_df.show(5)",
      "id": "795d332e-97c2-4e2c-b9ca-022fbd1bba11"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Prepare Training Data",
      "id": "9fc94098-e50e-4ebd-b8a2-16976e908f52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Define feature columns and target\nnumeric_features = [\n    \"CLAIM_AMOUNT\", \"COVERAGE_UTILIZATION_PCT\", \"DAYS_TO_REPORT\",\n    \"EXCEEDS_COVERAGE\", \"HIGH_VALUE\", \"VEHICLE_AGE\",\n    \"PREV_CLAIMS\", \"DRIVER_AGE\", \"YEARS_LICENSED\", \"CLAIM_PREMIUM_RATIO\"\n]\ncategorical_features = [\"CLAIM_TYPE\", \"POLICY_RISK_SCORE\", \"POLICY_TYPE\"]\ntarget = \"IS_FRAUD\"\n\nprint(f\"üìä Numeric features: {len(numeric_features)}\")\nprint(f\"üìä Categorical features: {len(categorical_features)}\")\nprint(f\"üéØ Target: {target}\")\n\n# Encode categorical variables using Snowflake ML\nencoder = OneHotEncoder(\n    input_cols=categorical_features,\n    output_cols=[f\"{c}_ENCODED\" for c in categorical_features],\n    drop_input_cols=True\n)\nencoded_df = encoder.fit(feature_df).transform(feature_df)\n\n# Scale numeric features\nscaler = StandardScaler(\n    input_cols=numeric_features,\n    output_cols=[f\"{c}_SCALED\" for c in numeric_features]\n)\nscaled_df = scaler.fit(encoded_df).transform(encoded_df)\n\n# Split data into train and test sets\ntrain_df, test_df = scaled_df.random_split([0.8, 0.2], seed=42)\nprint(f\"\\nüìä Training set: {train_df.count()} records\")\nprint(f\"üìä Test set: {test_df.count()} records\")",
      "id": "abe61bd2-cd08-475d-96a6-6a100832408c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Train Fraud Detection Model\n\nUsing Snowflake ML's RandomForestClassifier - training happens entirely within Snowflake.",
      "id": "9f717cc7-922b-4299-bd63-be9ce23a7cfc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Get all feature columns (scaled numeric + encoded categorical)\nfeature_cols = (\n    [f\"{c}_SCALED\" for c in numeric_features] + \n    [c for c in scaled_df.columns if \"_ENCODED\" in c and c != target]\n)\n\nprint(f\"üî¢ Total features for model: {len(feature_cols)}\")\n\n# Initialize and train Random Forest model\nrf_model = RandomForestClassifier(\n    input_cols=feature_cols,\n    label_cols=[target],\n    output_cols=[\"PREDICTION\"],\n    n_estimators=100,\n    max_depth=10,\n    random_state=42\n)\n\nprint(\"üöÄ Training Random Forest model...\")\nprint(\"   (All computation happens in Snowflake - data never leaves!)\")\n\n# Train the model\nrf_model.fit(train_df)\nprint(\"‚úÖ Model training complete!\")",
      "id": "bc8cd24d-d3f7-4e9f-ba6e-655080e7aafa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "",
      "id": "3f3ded16-0117-4b6b-90d7-5d979e02d1a5"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}